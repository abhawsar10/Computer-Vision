# -*- coding: utf-8 -*-
"""hw5_ab_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r0WX_y2Idg1dkdJq5T9MK7Vt3AM4MZ5o

Load Data from Drive
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip '/content/drive/MyDrive/CV_HW5/data_semantics.zip'

!unzip '/content/drive/MyDrive/CV_HW5/devkit_semantics.zip'

"""Data Splitting into Train, Test, Val

"""

import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torch.utils.data
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
import pandas as pd
import io
import os
import random
import shutil
from PIL import Image
import matplotlib.pyplot as plt
import cv2

import torchvision.models as models

DATA_PATH = './training/image_2/'
LABEL_PATH = './training/semantic/'

def split_data():

    i=0
    for img_name in sorted(os.listdir(DATA_PATH)):

        dir_train = 'data/images/train'
        dir_test = 'data/images/test'
        dir_val = 'data/images/val'

        try:
            os.makedirs(dir_train, exist_ok=True)
            os.makedirs(dir_test, exist_ok=True)
            os.makedirs(dir_val, exist_ok=True)

        except OSError as exc:
            if exc.errno == errno.EEXIST:
                pass

        if i<140:
            shutil.copy(DATA_PATH+"/"+img_name,dir_train+"/"+img_name)
        if i>=140 and i<170:
            shutil.copy(DATA_PATH+"/"+img_name,dir_val+"/"+img_name)
        if i>=170 and i<200:
            shutil.copy(DATA_PATH+"/"+img_name,dir_test+"/"+img_name)
        i+=1

    i=0
    for img_name in sorted(os.listdir(LABEL_PATH)):


        dir_train_label = 'data/labels/train'
        dir_test_label = 'data/labels/test'
        dir_val_label = 'data/labels/val'

        try:
            os.makedirs(dir_train_label, exist_ok=True)
            os.makedirs(dir_test_label, exist_ok=True)
            os.makedirs(dir_val_label, exist_ok=True)

        except OSError as exc:
            if exc.errno == errno.EEXIST:
                pass

        if i<140:
            shutil.copy(LABEL_PATH+"/"+img_name,dir_train_label+"/"+img_name)
        if i>=140 and i<170:
            shutil.copy(LABEL_PATH+"/"+img_name,dir_val_label+"/"+img_name)
        if i>=170 and i<200:
            shutil.copy(LABEL_PATH+"/"+img_name,dir_test_label+"/"+img_name)
        i+=1


split_data()

class my_Kitti_Dataset(Dataset):
    
    def __init__(self, images_dir, labels_dir, transformx=None, transformy=None, norm= True):
        super(my_Kitti_Dataset, self).__init__()
        self.images_dir = images_dir
        self.labels_dir = labels_dir
        self.transformx = transformx
        self.transformy = transformy
        self.norm=norm
        self.classes = 34
        self.imageAndLabel = self.getImageAndLabels(self.images_dir, self.labels_dir)
    

    def __len__(self):
        return len(self.imageAndLabel)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        if self.norm:

            im = Image.open(self.imageAndLabel[idx][0])
                # print("xyz",im.size)
                # PIL of size (1242, 375)
                
            
            im = self.transformx(im)
                # print("xyz1",im.shape)
                # Tensor of shape torch.Size([3, 256, 256]

            lbl = Image.open(self.imageAndLabel[idx][1])
            lbl = self.transformy(lbl)
            lbl = np.array(lbl, dtype=np.int32)        
            lbl[lbl == 255] = -1
            lbl = torch.from_numpy(lbl).long()

        else:

            im = Image.open(self.imageAndLabel[idx][0])
            im = self.transformx(im)            
            im = np.array(im, dtype=np.uint8)
            im = im[:, :, ::-1]  # RGB -> BGR
            im = im.astype(np.float64)
            im = im.transpose(2, 0, 1)
            im = torch.from_numpy(im).float()


            lbl = Image.open(self.imageAndLabel[idx][1])
            lbl = self.transformx(lbl)
            lbl = np.array(lbl, dtype=np.int32)
            lbl[lbl == 255] = -1
            lbl = torch.from_numpy(lbl).long()

            #a = transforms.Lambda(lambda image: torch.from_numpy(np.array(image).astype(np.float32)))
            #b= transforms.Lambda(lambda image: torch.from_numpy(np.array(image).astype(np.float32)).squeeze(0))



        #a = transforms.Lambda(lambda image: torch.from_numpy(np.array(image).astype(np.float32)))
        #b= transforms.Lambda(lambda image: torch.from_numpy(np.array(image).astype(np.float32)).squeeze(0))

        sample = {'images':im,
                    'labels': lbl}
        return sample
        
    def getImageAndLabels(self,imgpath,labpath):
        paths = []
        for iname in sorted(os.listdir(imgpath)):
            paths.append((imgpath+"/"+iname,labpath+"/"+iname))
        return paths

def find_mean_std(loader):

  sum, sumsq ,no =0,0,0

  for i,data in enumerate(loader): 
    x = data["images"]
    # print(x.shape)
    sum += torch.mean(x, dim=[0,2,3])
    sumsq +=torch.mean(x**2, dim=[0,2,3])
    no += 1

  # print("abccdef-",sum)
  # print("abcd-",no)
  # print("abcd-",i)

  mean = sum/no
  std = (sumsq/no - mean**2)**(1/2)

  return mean,std

def data_preproc():

    b=4
    tran = transforms.Compose([
	          transforms.ToTensor(),
            transforms.Resize((256,256))
             ])
    trany = transforms.Compose([
            transforms.Resize((256,256))
             ])

    train_set = my_Kitti_Dataset("./data/images/train/", "data/labels/train/",tran,trany, norm = True)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=b, shuffle=True, drop_last=True)
    m,s = find_mean_std(train_loader)

    # plt.imshow(  train_set.__getitem__(47)["images"].permute(1, 2, 0)  )
    # plt.show()

    print("before",m,s)
    tran1 = transforms.Compose([
	          transforms.ToTensor(),
            transforms.Resize((256,256)),
	          transforms.Normalize(m,s)
             ])
    train_set = my_Kitti_Dataset("./data/images/train/", "data/labels/train/",tran1,trany, norm = True)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=b, shuffle=True, drop_last=True)
    print("after",find_mean_std(train_loader))

    # plt.imshow(  train_set.__getitem__(47)["images"].permute(1, 2, 0)  )
    # plt.show()

    train_set = my_Kitti_Dataset("./data/images/val/", "data/labels/val/",tran,trany, norm = True)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=b, shuffle=True, drop_last=True)
    m,s = find_mean_std(train_loader)
    print("before",m,s)
    tran1 = transforms.Compose([
	          transforms.ToTensor(),
            transforms.Resize((256,256)),
	          transforms.Normalize(m,s)
             ])
    val_set = my_Kitti_Dataset("./data/images/val/", "data/labels/val/",tran1,trany,norm = True)
    val_loader = torch.utils.data.DataLoader(val_set, batch_size=b, shuffle=True, drop_last=True)
    print("after",find_mean_std(val_loader))



    train_set = my_Kitti_Dataset("./data/images/test/", "data/labels/test/",tran,trany, norm = True)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=b, shuffle=True, drop_last=True)
    m,s = find_mean_std(train_loader)
    print("before",m,s)
    tran1 = transforms.Compose([
	          transforms.ToTensor(),
            transforms.Resize((256,256)),
	          transforms.Normalize(m,s)
             ])
    test_set = my_Kitti_Dataset("./data/images/test/", "data/labels/test/",tran1,trany,norm = True)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=b, shuffle=True, drop_last=True)
    print("after",find_mean_std(test_loader))


    # print(train_set.__getitem__(0)["images"].shape)
    # print(train_set.__getitem__(0)["labels"].shape)

    

    return train_loader,val_loader,test_loader

def get_upsampling_weight(in_channels, out_channels, kernel_size):
    """Make a 2D bilinear kernel suitable for upsampling"""
    factor = (kernel_size + 1) // 2
    if kernel_size % 2 == 1:
        center = factor - 1
    else:
        center = factor - 0.5
    og = np.ogrid[:kernel_size, :kernel_size]
    filt = (1 - abs(og[0] - center) / factor) * \
           (1 - abs(og[1] - center) / factor)
    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),
                      dtype=np.float64)
    weight[range(in_channels), range(out_channels), :, :] = filt
    return torch.from_numpy(weight).float()

res_model = models.resnet18(pretrained=True)

# Freezing the layers except fc layers
cnt = 0
for elem in res_model.children():
    cnt+=1
    if(cnt <=8):
        for param in elem.parameters():
            param.requires_grad = False

class FCN32(torch.nn.Module):

    def __init__(self):
        super(FCN32, self).__init__()

        self.features = nn.Sequential(*list(res_model.children())[0:-2])
        self.features[0].padding=(100,100)
        self.avgpool = nn.AvgPool2d(kernel_size=7,stride=1)
        self.conv_last = nn.Conv2d(512, 34, kernel_size=1)
        self.upsampling34 = nn.ConvTranspose2d(34,34,kernel_size=64,stride=32, bias=False)
        self._initialize_weights()
        
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m,nn.ConvTranspose2d):
                assert m.kernel_size[0] == m.kernel_size[1]
                initial_weight = get_upsampling_weight(m.in_channels,m.out_channels,m.kernel_size[0])
                m.weight.data.copy_(initial_weight)

    def forward(self, x):

        tran = transforms.Compose([
            transforms.Resize((x.size()[2],x.size()[3]))
             ])

        o=x
        o = self.features(o)
        o = self.avgpool(o)
        o = self.conv_last(o)
        o = self.upsampling34(o)
        cx = int((o.shape[3] - x.shape[3]) / 2)
        cy = int((o.shape[2] - x.shape[2]) / 2)
        o = o[:, :, cy:cy + x.size()[2], cx:cx + x.size()[3]]
        return o
        
seg_model = FCN32()

seg_model.to('cuda')

def label_accuracy_score(label_trues, label_preds, n_class):
  
    hist = np.zeros((n_class, n_class))
    for lt, lp in zip(label_trues, label_preds):
        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)
    acc = np.diag(hist).sum() / hist.sum()
    with np.errstate(divide='ignore', invalid='ignore'):
        acc_cls = np.diag(hist) / hist.sum(axis=1)
    acc_cls = np.nanmean(acc_cls)
    with np.errstate(divide='ignore', invalid='ignore'):
        iu = np.diag(hist) / (
            (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)).astype(np.float32)
        )

    mean_iou = np.nanmean(iu)
    freq = hist.sum(axis=1) / hist.sum()
    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()
    return acc, acc_cls, mean_iou, fwavacc

def _fast_hist(label_true, label_pred, n_class):
    mask = (label_true >= 0) & (label_true < n_class)
    hist = np.bincount(
        n_class * label_true[mask].astype(int) +
        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)
    return hist

def cross_entropy2d(input, target):
    n, c, h, w = input.size()

    input = input.transpose(1, 2).transpose(2, 3).contiguous()
    input = input[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]
    input = input.view(-1, c)

    # target: (n*h*w,)
    mask = target >= 0.0
    target = target[mask]

    func_loss = torch.nn.CrossEntropyLoss()
    loss = func_loss(input, target)

    return loss

def data_preproc_no_norm():

    b=4
    tran = transforms.Compose([
            transforms.Resize((375, 1242))
             ])

    train_set = my_Kitti_Dataset("./data/images/train/", "data/labels/train/",tran,tran, norm = False)
    # print(train_set.__getitem__(0))
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=b, shuffle=True, drop_last=True)

    val_set = my_Kitti_Dataset("./data/images/val/", "data/labels/val/",tran,tran,norm = False)
    val_loader = torch.utils.data.DataLoader(val_set, batch_size=b, shuffle=True, drop_last=True)

    test_set = my_Kitti_Dataset("./data/images/test/", "data/labels/test/",tran,tran,norm = False)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=b, shuffle=True, drop_last=True)

    # print("after",find_mean_std(train_loader))
    # print("after",find_mean_std(val_loader))
    # print("after",find_mean_std(test_loader))

    
    
    # print(train_set.__getitem__(0))

    return train_loader,val_loader,test_loader



train_loader,valid_loader,test_loader = data_preproc_no_norm()
# train_loader,valid_loader,test_loader = data_preproc()

torch.cuda.empty_cache()

def train(train_loader,val_loader, model,E=10,LR=0.01):

    
    from torch.utils.tensorboard import SummaryWriter
    tensor_writer = SummaryWriter()

    optimizer = torch.optim.Adam(seg_model.parameters(),lr=LR)
    
    epochs = E
    max_miou = 0.0
    PATH = './model.pth'

    for epoch in range(epochs):  
        print("Epoch:",epoch)
        running_loss = 0.0
        for i, data in enumerate(train_loader, 0):
            
            model.train()
            inputs, labels = data['images'].cuda(), data['labels'].cuda()
            torch.cuda.empty_cache()
            optimizer.zero_grad()
            outputs = model(inputs)

            loss = cross_entropy2d(outputs, labels)

            #backprop
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            
            predicted = outputs.data.max(1)[1].cpu().numpy()[:, :, :]

            ground_truth = labels.data.cpu().numpy()

            acc, acc_cls, mean_iou, fwavacc = label_accuracy_score(ground_truth, predicted, n_class=outputs.shape[1])
            
            tensor_writer.add_scalar("Loss/train", running_loss, epoch)
            tensor_writer.add_scalar("acc/train", acc, epoch)
            tensor_writer.add_scalar('mean_iou/train',mean_iou,  epoch) 
            
        if epoch % 1 == 0:  

            val_acc = 0.0
            correct = 0
            total = 0
            val_loss = 0
            mmiou = 0
            with torch.no_grad():

                #calculate the validation loss
                for i, data in enumerate(val_loader,0):
                  
                    model.eval()
                    inputs, labels = data['images'].cuda(), data['labels'].cuda()
                    val_outputs = model(inputs)
                    val_loss += cross_entropy2d(val_outputs, labels).item()
                    val_predicted = val_outputs.data.max(1)[1].cpu().numpy()[:, :, :]
                    val_ground_truth = labels.data.cpu().numpy()
                    
                    val_acc, val_acc_cls, val_mean_iou, val_fwavacc = label_accuracy_score(val_ground_truth, val_predicted, n_class=val_outputs.shape[1])

                    mmiou += val_mean_iou
                    
                    tensor_writer.add_scalar("acc/val", val_acc, epoch)
                    tensor_writer.add_scalar('mean_iou/val',val_mean_iou,  epoch) 
                    
            
            if mmiou/(i+1) > max_miou:
                max_miou = mmiou/(i+1)
                torch.save(model.state_dict(),PATH)
            print("Epoch:",epoch,"---Train Loss: ",running_loss/(i+1),"---Val Loss: ",val_loss/(i+1),"---Val Acc: ",val_acc,"---MIOU:",mmiou/(i+1))
        
    tensor_writer.close()
    print('Finished Training')
    print("Best miou:",max_miou)

train(train_loader,valid_loader,seg_model,E=20,LR=0.005)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir runs

def predict_an_image(path="inp.png",norm=False):


  seg_model = FCN32()
  PATH = './model.pth'
  seg_model.to('cuda')
  seg_model.load_state_dict(torch.load(PATH))


  m,s = find_mean_std(test_loader)
  # print(train_set.__getitem__(0))
  tran1 = transforms.Compose([
          transforms.ToTensor(),
          transforms.Resize((256,256)),
          transforms.Normalize(m,s)
            ])
  tran = transforms.Compose([
            transforms.Resize((375, 1242))
             ])
  if norm:

      img = Image.open(path)
      # print(img.size[0])
      # print(img.size[1])

      ori_height = img.size[0]
      ori_width = img.size[1]
      model_width = 256
      model_height = 256
      
      img = tran1(img)

      seg_model.eval()
      

      img = np.array(img)
      data = img[None, :, :, :]
      data = torch.from_numpy(data).float()
      data = data.cuda()
      out = seg_model(data)
          # tensor of size torch.Size([1, 35, 256, 256])

      lbl_pred = out.data.max(1)[1].cpu().numpy()[:, :, :]
          #np of shape (1, 256, 256)
      lbl_pred = lbl_pred.transpose((1, 2, 0))
          #np of shape lbs (256, 256, 1)
      lbl_pred = lbl_pred.reshape(model_height, model_width)
          #np of shape lbs1 (256, 256)

      n_classes = np.max(lbl_pred)
      height = lbl_pred.shape[0]
      width = lbl_pred.shape[1]
      seg_img = np.zeros((height, width, 3))

      for i in range(len(lbl_pred)):
          for j in range(len(lbl_pred[i])):
              seg_img[i][j][0] = labels.id2label[lbl_pred[i][j]].color[2]
              seg_img[i][j][1] = labels.id2label[lbl_pred[i][j]].color[1]
              seg_img[i][j][2] = labels.id2label[lbl_pred[i][j]].color[0]


          #seg_img is of shape (256, 256, 3)
      if model_width != ori_width or model_height != ori_height:
          seg_img = cv2.resize(seg_img, (ori_height, ori_width ), interpolation=cv2.INTER_NEAREST)

      cv2.imwrite("out.png", seg_img)
      imgagain = cv2.imread("out.png", flags=cv2.IMREAD_COLOR)
  
  else:
      
      im = Image.open(path)
      im = tran(im)            
      im = np.array(im, dtype=np.uint8)
      im = im[:, :, ::-1]  # RGB -> BGR
      im = im.astype(np.float64)
      im = im.transpose(2, 0, 1)
      im = im[None,:,:,:]
      im = torch.from_numpy(im).float()    
      data = im.cuda() 

      seg_model.eval()
      """
      inputpth = path

      img = cv2.imread(inputpth, flags=cv2.IMREAD_COLOR)
      ori_height = img.shape[0]
      ori_width = img.shape[1]
      model_width = 256
      model_height = 256
      
      # if model_width != ori_width or model_height != ori_height:
      #   img = cv2.resize(img, (model_width, model_height), interpolation=cv2.INTER_NEAREST)

      data = im.transpose((2, 0, 1))
      data = im[None, :, :, :]
      data = torch.from_numpy(data).float()
      data = data.cuda()
      """
      out = seg_model(data)
      
      lbl_pred = out.data.max(1)[1].cpu().numpy()[:, :, :]
      lbl_pred = lbl_pred.transpose((1, 2, 0))
      print(lbl_pred.shape)
      # lbl_pred = lbl_pred.reshape(model_height, model_width)

      height = lbl_pred.shape[0]
      width = lbl_pred.shape[1]
      seg_img = np.zeros((height, width, 3))

      for i in range(len(lbl_pred)):
          for j in range(len(lbl_pred[i])):
              seg_img[i][j][0] = labels.id2label[lbl_pred[i][j][0]].color[2]
              seg_img[i][j][1] = labels.id2label[lbl_pred[i][j][0]].color[1]
              seg_img[i][j][2] = labels.id2label[lbl_pred[i][j][0]].color[0]
              
      # if model_width != ori_width or model_height != ori_height:
      #     seg_img = cv2.resize(seg_img, (ori_width,ori_height), interpolation=cv2.INTER_NEAREST)

      cv2.imwrite("out.png", seg_img)

from devkit.helpers import labels
predict_an_image(path="/content/data/images/test/000181_10.png",norm=False)

def predict_test(loader,model):

  val_loss=0
  mmiou = 0
  macc = 0

  with torch.no_grad():
    for i, data in enumerate(loader,0):
        inputs, labels = data['images'].cuda(), data['labels'].cuda()
        
        val_outputs = model(inputs)
        val_loss += cross_entropy2d(val_outputs, labels).item()
        val_predicted = val_outputs.data.max(1)[1].cpu().numpy()[:, :, :]
        val_ground_truth = labels.data.cpu().numpy()
        val_acc, val_acc_cls, val_mean_iou, val_fwavacc = label_accuracy_score(val_ground_truth, val_predicted, n_class=val_outputs.shape[1])
        # print(val_mean_iou)
        mmiou += val_mean_iou
        macc += val_acc


  return mmiou/(i+1),macc/(i+1)

predict_test(valid_loader,seg_model)

def get_upsampling_weight(in_channels, out_channels, kernel_size):
    factor = (kernel_size + 1) // 2
    if kernel_size % 2 == 1:
        center = factor - 1
    else:
        center = factor - 0.5
    og = np.ogrid[:kernel_size, :kernel_size]
    filt = (1 - abs(og[0] - center) / factor) * \
           (1 - abs(og[1] - center) / factor)
    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),
                      dtype=np.float64)
    weight[range(in_channels), range(out_channels), :, :] = filt
    return torch.from_numpy(weight).float().cuda()

res_model = models.resnet18(pretrained=True)
 
# Freezing the layers except fc layers
cnt = 0
for elem in res_model.children():
    cnt+=1
    if(cnt <=8):
        for param in elem.parameters():
            param.requires_grad = False
 
#Creating FCN custom model.
class FCN16(nn.Module):
    def __init__(self):
        super(FCN16,self).__init__()
 
        self.features = nn.Sequential(*list(res_model.children())[0:-2])
        self.features[0].padding = (100,100)
        self.classifier = nn.Sequential(
                                    nn.AvgPool2d(kernel_size=(7,7),stride=1),
                                    nn.Conv2d(512, 34, kernel_size=1)
        )
        self.upscore0 = nn.ConvTranspose2d(34,34,4,stride=2,bias=False)
        self.upscore1 = nn.ConvTranspose2d(34,34,32,stride=16,bias=False)
        self.score_pool4 = nn.Conv2d(256,34, kernel_size=1)
        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.ConvTranspose2d):
                assert m.kernel_size[0] == m.kernel_size[1]
                initial_weight = get_upsampling_weight(
                    m.in_channels, m.out_channels, m.kernel_size[0])
                m.weight.data.copy_(initial_weight)
 
    def forward(self,x):
 
        h = x
        for i in range(len(self.features)):
            h = self.features[i](h)
            if i == 6:
                pool4 = h
        h = self.classifier(h)
        h = self.upscore0(h)
        upsc2 = h
        h = self.score_pool4(pool4)
        h = h[:, :, 5:5 + upsc2.size()[2], 5:5 + upsc2.size()[3]]
        scpool4 = h
 
 
        h = upsc2+scpool4
        h = self.upscore1(h)
        cx = int((h.shape[3] - x.shape[3]) / 2)
        cy = int((h.shape[2] - x.shape[2]) / 2)
        h = h[:, :, cy:cy + x.size()[2], cx:cx + x.size()[3]]
 
        return h
 
seg_model_16 = FCN16()
seg_model_16.to('cuda')

train(train_loader,valid_loader,seg_model_16,E=3)

def predict_an_image(path="inp.png",norm=True):


    seg_model = FCN16()
    PATH = './model.pth'
    seg_model.to('cuda')
    seg_model.load_state_dict(torch.load(PATH))


    tran = transforms.Compose([
        transforms.Resize((375, 1242))
            ])


    im = Image.open(path)
    im = tran(im)            
    im = np.array(im, dtype=np.uint8)
    im = im[:, :, ::-1]  # RGB -> BGR
    im = im.astype(np.float64)
    im = im.transpose(2, 0, 1)
    im = im[None,:,:,:]
    im = torch.from_numpy(im).float()    
    data = im.cuda() 
    seg_model.eval()

    out = seg_model(data)

    lbl_pred = out.data.max(1)[1].cpu().numpy()[:, :, :]
    lbl_pred = lbl_pred.transpose((1, 2, 0))

    height = lbl_pred.shape[0]
    width = lbl_pred.shape[1]
    seg_img = np.zeros((height, width, 3))

    for i in range(len(lbl_pred)):
        for j in range(len(lbl_pred[i])):
            seg_img[i][j][0] = labels.id2label[lbl_pred[i][j][0]].color[2]
            seg_img[i][j][1] = labels.id2label[lbl_pred[i][j][0]].color[1]
            seg_img[i][j][2] = labels.id2label[lbl_pred[i][j][0]].color[0]
        
    cv2.imwrite("out.png", seg_img)



predict_an_image(norm=False)

seg_model_16 = FCN16()
PATH = './model.pth'
seg_model_16.to('cuda')
seg_model_16.load_state_dict(torch.load(PATH))
predict_test(test_loader,seg_model_16)